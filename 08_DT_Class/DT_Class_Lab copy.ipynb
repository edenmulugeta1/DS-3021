{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You just graduated UVA's BSDS program and got a job working at a movie studio in Hollywood. \n",
    "\n",
    "Your boss is the head of the studio and wants to know if they can gain a competitive advantage by predicting new movies that might get high imdb scores (movie rating). \n",
    "\n",
    "You would like to be able to explain the model to mere mortals but need a fairly robust and flexible approach so you've chosen to use decision trees to get started. \n",
    "\n",
    "In doing so, similar to  great data scientists of the past you remembered the excellent education provided to you at UVA in a undergrad data science course and have outline 20ish steps that will need to be undertaken to complete this task. As always, you will need to make sure to #comment your work heavily. \n",
    "\n",
    " Footnotes: \n",
    "-\tYou can add or combine steps if needed\n",
    "-\tAlso, remember to try several methods during evaluation and always be mindful of how the model will be used in practice.\n",
    "- Make sure all your variables are the correct type (factor, character,numeric, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/DS-3021/08_DT_Class\n",
      "['Classification and regression trees_Loh.pdf', 'clinical_breast_cleaned.csv', 'Decision Trees.ipynb', 'Decision Trees.py', 'Decision_Trees_10.20.22.pptx', 'Decision_Trees_3.24.22.pptx', 'Decision_Trees_4.28.21.pdf', 'DT_Class_Lab copy.ipynb', 'DT_Class_Lab.ipynb', 'heart_failure.csv', 'parent.csv', 'pregnancy.csv', 'Week 08 conversion doc.docx', '~$Decision_Trees_10.20.22.pptx']\n",
      "['/workspaces/DS-3021/data/movie_metadata.csv']\n"
     ]
    }
   ],
   "source": [
    "# done to see workspace (file paths)\n",
    " \n",
    "print(os.getcwd())\n",
    "print(os.listdir())\n",
    "\n",
    "# Searching for the file \"movie_metadata.csv\"\n",
    "file_path = glob.glob('/workspaces/DS-3021/**/movie_metadata.csv', recursive=True)\n",
    "print(file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "# Sometimes need to set the working directory back out of a folder that we create a file in\n",
    "\n",
    "# import os\n",
    "# os.listdir()\n",
    "# print(os.getcwd())\n",
    "# os.chdir('c:\\\\Users\\\\Brian Wright\\\\Documents\\\\3001Python\\\\DS-3001')\n",
    "\n",
    "movie_metadata = pd.read_csv(\"../data/movie_metadata.csv\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Ensure all the variables are classified correctly including the target variable and collapse factor variables as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color                         object\n",
      "director_name                 object\n",
      "num_critic_for_reviews       float64\n",
      "duration                     float64\n",
      "director_facebook_likes      float64\n",
      "actor_3_facebook_likes       float64\n",
      "actor_2_name                  object\n",
      "actor_1_facebook_likes       float64\n",
      "gross                        float64\n",
      "genres                        object\n",
      "actor_1_name                  object\n",
      "movie_title                   object\n",
      "num_voted_users                int64\n",
      "cast_total_facebook_likes      int64\n",
      "actor_3_name                  object\n",
      "facenumber_in_poster         float64\n",
      "plot_keywords                 object\n",
      "movie_imdb_link               object\n",
      "num_user_for_reviews         float64\n",
      "language                      object\n",
      "country                       object\n",
      "content_rating                object\n",
      "budget                       float64\n",
      "title_year                   float64\n",
      "actor_2_facebook_likes       float64\n",
      "imdb_score                   float64\n",
      "aspect_ratio                 float64\n",
      "movie_facebook_likes           int64\n",
      "dtype: object\n",
      "\n",
      "Numeric Columns: ['num_critic_for_reviews', 'duration', 'director_facebook_likes', 'actor_3_facebook_likes', 'actor_1_facebook_likes', 'gross', 'num_voted_users', 'cast_total_facebook_likes', 'facenumber_in_poster', 'num_user_for_reviews', 'budget', 'title_year', 'actor_2_facebook_likes', 'imdb_score', 'aspect_ratio', 'movie_facebook_likes']\n",
      "\n",
      "Categorical Columns: ['color', 'director_name', 'actor_2_name', 'genres', 'actor_1_name', 'movie_title', 'actor_3_name', 'plot_keywords', 'movie_imdb_link', 'language', 'country', 'content_rating']\n",
      "\n",
      "Data type of imdb_score: float64\n"
     ]
    }
   ],
   "source": [
    "# Checking data types of all columns\n",
    "print(movie_metadata.dtypes)\n",
    "\n",
    "# Identifying numeric and categorical variables\n",
    "numeric_columns = movie_metadata.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_columns = movie_metadata.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"\\nNumeric Columns:\", numeric_columns)\n",
    "print(\"\\nCategorical Columns:\", categorical_columns)\n",
    "\n",
    "# Making sure that 'imdb_score' is numeric\n",
    "print(\"\\nData type of imdb_score:\", movie_metadata['imdb_score'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Check for missing variables and correct as needed. Once you've completed the cleaning again create a function that will do this for you in the future. In the submission, include only the function and the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " color                       19\n",
      "director_name              104\n",
      "num_critic_for_reviews      50\n",
      "duration                    15\n",
      "director_facebook_likes    104\n",
      "actor_3_facebook_likes      23\n",
      "actor_2_name                13\n",
      "actor_1_facebook_likes       7\n",
      "gross                      884\n",
      "actor_1_name                 7\n",
      "actor_3_name                23\n",
      "facenumber_in_poster        13\n",
      "plot_keywords              153\n",
      "num_user_for_reviews        21\n",
      "language                    14\n",
      "country                      5\n",
      "content_rating             303\n",
      "budget                     492\n",
      "title_year                 108\n",
      "actor_2_facebook_likes      13\n",
      "aspect_ratio               329\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "missing_values = movie_metadata.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after cleaning:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "# Handling missing vlaues with function\n",
    "# Filling catagorical columns with their mode and numeric columns with their median\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    # categorical columns with mode\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0] if df[col].mode().size > 0 else \"Unknown\")\n",
    "    \n",
    "    # numeric columns with median\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    return df\n",
    "\n",
    "movie_metadata = handle_missing_values(movie_metadata)\n",
    "\n",
    "# Making sure that there are no missing values\n",
    "print(\"Missing values after cleaning:\\n\", movie_metadata.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Guess what, you don't need to scale the data, because DTs don't require this to be done, they make local greedy decisions...keeps getting easier, go to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 Determine the baserate or prevalence for the classifier, what does this number mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevalence of high IMDb scores (7 or higher): 0.3526\n"
     ]
    }
   ],
   "source": [
    "# Creating a binary target based on imdb_score \n",
    "movie_metadata['high_imdb_score'] = movie_metadata['imdb_score'] >= 7\n",
    "\n",
    "# Calculating prevalence or the baserate of high IMDb score\n",
    "prevalence = movie_metadata['high_imdb_score'].mean()\n",
    "print(f\"Prevalence of high IMDb scores (7 or higher): {prevalence:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prevalence is the proportion of instances where the target variable (e.g., \"high IMDb score\") occurs in the dataset. The prevalence is 0.3 meaning 30% of the movies have a high IMDb score (7 or above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 Split your data into test, tune, and train. (80/10/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 4034\n",
      "Tune set size: 505\n",
      "Test set size: 504\n"
     ]
    }
   ],
   "source": [
    "# Define the target column \n",
    "target_column = 'high_imdb_score'  \n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = movie_metadata.drop(columns=[target_column])  # Drop the target column to get features\n",
    "y = movie_metadata[target_column]  \n",
    "\n",
    "# Splitting into train (80%) and then remaining into test and tune (20%) \n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting the remaining 20% into test (50%) and tune (50%) and giving 10% for both\n",
    "X_test, X_tune, y_test, y_tune = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Looking over the sizes of the splits\n",
    "print(f\"Train set size: {len(X_train)}\")\n",
    "print(f\"Tune set size: {len(X_tune)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 Create the kfold object for cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Train indices: [0 1 2 3 4]...\n",
      "Validation indices: [ 6  8 12 14 17]...\n",
      "----------------------------------------\n",
      "Fold 2:\n",
      "Train indices: [1 2 3 4 5]...\n",
      "Validation indices: [ 0  7 22 31 41]...\n",
      "----------------------------------------\n",
      "Fold 3:\n",
      "Train indices: [0 1 3 4 5]...\n",
      "Validation indices: [ 2 13 18 20 37]...\n",
      "----------------------------------------\n",
      "Fold 4:\n",
      "Train indices: [0 1 2 4 6]...\n",
      "Validation indices: [ 3  5  9 10 15]...\n",
      "----------------------------------------\n",
      "Fold 5:\n",
      "Train indices: [0 2 3 5 6]...\n",
      "Validation indices: [ 1  4 11 16 19]...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Setting the number of folds \n",
    "k = 5\n",
    "\n",
    "# Creating the KFold object which will be used for cross-validation \n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Examples to check \n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train, y_train), 1):\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"Train indices: {train_idx[:5]}...\") \n",
    "    print(f\"Validation indices: {val_idx[:5]}...\")  \n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 Create the scoring metric you will use to evaluate your model and the max depth hyperparameter (grid search) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth from grid search: 1\n"
     ]
    }
   ],
   "source": [
    "# Identifying categorical columns within X_train\n",
    "categorical_columns = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Applying one-hot encoding to categorical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "# Transforming X_train and X_tune\n",
    "X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "X_tune_encoded = preprocessor.transform(X_tune)\n",
    "\n",
    "# Setting the parameter grid for max_depth\n",
    "param_grid = {'max_depth': range(1, 21)}\n",
    "\n",
    "# Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# GridSearchCV with the classifier, parameter grid, and cross-validation\n",
    "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=kfold, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Gridsearch and output of best hyperparameter value\n",
    "grid_search.fit(X_train_encoded, y_train)\n",
    "print(f\"Best max_depth from grid search: {grid_search.best_params_['max_depth']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 Build the classifier object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Decision Tree classifier object \n",
    "dt_model = DecisionTreeClassifier(max_depth=grid_search.best_params_['max_depth'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 Use the kfold object and the scoring metric to find the best hyperparameter value for max depth via the grid search method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was already done in step 8 with GridSearchCV. \n",
    "# The grid search finds the best hyperparameter and stores it in grid_search.best_params_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11 Fit the model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(max_depth=1, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=1, random_state=42)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the decision tree to the whole training data with the best hyperparameter\n",
    "dt_model.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 What is the best depth value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best max_depth: {grid_search.best_params_['max_depth']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13 Print out the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- remainder__imdb_score <= 6.95\n",
      "|   |--- class: False\n",
      "|--- remainder__imdb_score >  6.95\n",
      "|   |--- class: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting feature names after one-hot encoding\n",
    "encoded_feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# The strucuture of the decision tree\n",
    "tree_structure = export_text(dt_model, feature_names=encoded_feature_names)\n",
    "print(tree_structure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14 View the results, comment on how the model performed using the metrics you selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Predicting on the training data using the encoded features\n",
    "y_train_pred = dt_model.predict(X_train_encoded)\n",
    "\n",
    "# Calculating accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[2617    0]\n",
      " [   0 1417]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has a training accuracy of 1.0000, meaning it perfectly predicts the training data. However, this might mean the model is overfitting and could perform worse on new, unseen data. Therefore, checking the test set performance is important to confirm this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15 Which variables appear to be contributing the most (variable importance) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Feature  Importance\n",
      "22095                              remainder__imdb_score         1.0\n",
      "0                            cat__color_ Black and White         0.0\n",
      "14729  cat__plot_keywords_alien|creature|future|outer...         0.0\n",
      "14737  cat__plot_keywords_alien|estranged couple|ocea...         0.0\n",
      "14736  cat__plot_keywords_alien|escape|manager|neighb...         0.0\n",
      "...                                                  ...         ...\n",
      "7364                  cat__movie_title_A Scanner Darkly          0.0\n",
      "7363                cat__movie_title_A Room with a View          0.0\n",
      "7362            cat__movie_title_A Room for Romeo Brass          0.0\n",
      "7361          cat__movie_title_A Prairie Home Companion          0.0\n",
      "22097                    remainder__movie_facebook_likes         0.0\n",
      "\n",
      "[22098 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Getting feature importances\n",
    "importances = dt_model.feature_importances_\n",
    "\n",
    "# Creating a DataFrame to see feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': encoded_feature_names,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sorting by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature remainder__imdb_score has the highest importance score of 1.0, meaning it is the most important variable in predicting the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16 Use the predict method on the tune data and print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Set Predictions:\n",
      "[ True False False False False False False  True False False False False\n",
      " False False False False  True False  True  True False False False False\n",
      "  True False  True False  True False False False False False False  True\n",
      "  True False False  True False False False False False False False  True\n",
      " False  True  True  True False False  True  True False  True  True False\n",
      "  True False False False False False False False  True  True  True  True\n",
      "  True False False False False False  True False False False False  True\n",
      " False  True  True False False False  True False False  True  True False\n",
      " False  True False False  True False False  True False  True  True False\n",
      " False  True False False  True False  True False False False  True  True\n",
      " False False False False  True  True False False False  True False False\n",
      "  True False False False  True  True  True False False False False False\n",
      " False False False False  True False False  True  True False False False\n",
      "  True  True  True False False False False False False  True  True  True\n",
      "  True False  True False False  True False  True  True False  True False\n",
      " False False False  True  True False False False  True  True False False\n",
      " False False  True False False False  True False  True False False  True\n",
      "  True False False  True False False  True  True False  True False  True\n",
      "  True  True False  True False False False False  True  True  True False\n",
      " False False False  True  True False  True False False False  True False\n",
      "  True False False  True False  True  True  True False False False False\n",
      " False  True False False  True  True False  True  True False False  True\n",
      "  True False False False False  True  True False  True False  True False\n",
      " False False False False  True  True  True False False False  True  True\n",
      " False False  True  True False False False False False False False False\n",
      " False False False  True  True False False  True False  True  True False\n",
      "  True False  True False  True False False False False False False False\n",
      "  True False  True  True False  True  True False False  True False  True\n",
      "  True False False False  True False False  True False False False False\n",
      " False False False False  True False  True False False False False  True\n",
      "  True  True  True  True  True  True  True False  True False  True False\n",
      " False False False False False False False  True  True  True  True False\n",
      " False False False  True False False False  True False False  True  True\n",
      " False False False False False False False  True False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False  True False  True  True False  True\n",
      "  True  True  True  True False False False  True False  True  True False\n",
      "  True False False False False False False False False False  True False\n",
      " False  True False False  True False  True  True  True  True  True False\n",
      "  True False  True False False  True False  True  True False False False\n",
      "  True False False False  True  True False False  True False False  True\n",
      " False False False False  True False False False False False False  True\n",
      " False]\n"
     ]
    }
   ],
   "source": [
    "# Transforming the tuning set using the preprocessor\n",
    "X_tune_encoded = preprocessor.transform(X_tune)\n",
    "\n",
    "# Predicting on the tuning set\n",
    "y_tune_pred = dt_model.predict(X_tune_encoded)\n",
    "\n",
    "# Printing predictions\n",
    "print(f\"Tuning Set Predictions:\\n{y_tune_pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17 How does the model perform on the tune data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Set Accuracy: 1.0000\n",
      "Confusion Matrix for Tuning Set:\n",
      " [[322   0]\n",
      " [  0 183]]\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of tuning set\n",
    "tune_accuracy = accuracy_score(y_tune, y_tune_pred)\n",
    "print(f\"Tuning Set Accuracy: {tune_accuracy:.4f}\")\n",
    "\n",
    "# Confusion matrix for the tuning set\n",
    "cm_tune = confusion_matrix(y_tune, y_tune_pred)\n",
    "print(\"Confusion Matrix for Tuning Set:\\n\", cm_tune)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that the model is making perfect predictions on the tuning set, with no errors. However, might signify overfitting and is also important to check performance on test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18 Print out the confusion matrix for the tune data, what does it tell you about the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Tuning Set:\n",
      " [[322   0]\n",
      " [  0 183]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix for tuning set\n",
    "cm_tune = confusion_matrix(y_tune, y_tune_pred)\n",
    "print(\"Confusion Matrix for Tuning Set:\\n\", cm_tune)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model shows perfect accuracy on the test set as well and it suggests that the model is overfitting, meaning it might have memorized the data rather than learning to generalize. While it performs well on known data, it could struggle with new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19 What are the top 3 movies based on the tune set? Which variables are most important in predicting the top 3 movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         movie_title  imdb_score  high_imdb_score\n",
      "112                    Transformers          7.1             True\n",
      "83   Dawn of the Planet of the Apes          7.6             True\n",
      "0                            Avatar          7.9             True\n",
      "                                                 Feature  Importance\n",
      "22101                              remainder__imdb_score         1.0\n",
      "0                            cat__color_ Black and White         0.0\n",
      "14733  cat__plot_keywords_alien|crash|planet|prison|s...         0.0\n"
     ]
    }
   ],
   "source": [
    "# Getting the top 3 movies that are predicted to have a high IMDb score\n",
    "top_3_movies = movie_metadata.iloc[y_tune_pred.argsort()[-3:]]  \n",
    "print(top_3_movies[['movie_title', 'imdb_score', 'high_imdb_score']])\n",
    "\n",
    "# Checking variables most important to predict\n",
    "print(importance_df.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 Use a different hyperparameter for the grid search function and go through the process above again using the tune set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best min_samples_split: 2\n"
     ]
    }
   ],
   "source": [
    "param_grid_min_samples = {'min_samples_split': [2, 5, 10, 20]}\n",
    "\n",
    "# Creating GridSearchCV with new hyperparameter\n",
    "grid_search_min_samples = GridSearchCV(estimator=dt_model, param_grid=param_grid_min_samples, \n",
    "                                       scoring='accuracy', cv=kfold, n_jobs=-1)\n",
    "\n",
    "# Fitting the grid search to the preprocessed data\n",
    "grid_search_min_samples.fit(X_train_encoded, y_train)\n",
    "\n",
    "# The best hyperparameter value for min_samples_split\n",
    "print(f\"Best min_samples_split: {grid_search_min_samples.best_params_['min_samples_split']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21 Did the model improve with the new hyperparameter search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Tuning Set Accuracy with min_samples_split: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Fiting the model with the new best parameter\n",
    "dt_model_min_samples = DecisionTreeClassifier(min_samples_split=grid_search_min_samples.best_params_['min_samples_split'], random_state=42)\n",
    "dt_model_min_samples.fit(X_train_encoded, y_train)  \n",
    "\n",
    "# Evaluating performance on the tuning set\n",
    "y_tune_pred_min_samples = dt_model_min_samples.predict(X_tune_encoded) \n",
    "tune_accuracy_min_samples = accuracy_score(y_tune, y_tune_pred_min_samples)\n",
    "print(f\"New Tuning Set Accuracy with min_samples_split: {tune_accuracy_min_samples:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22 Using the better model, predict the test data and print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Predictions:\n",
      "[ True False False False False  True  True False False False False  True\n",
      " False  True False  True False False  True  True  True False False False\n",
      "  True False False False  True False  True False  True False False False\n",
      " False False False  True False  True False  True  True False False False\n",
      " False False False False  True  True  True False False False False False\n",
      " False False  True  True False False False  True  True False False False\n",
      "  True False False  True  True False  True  True  True False False  True\n",
      " False False False False False  True  True False False  True False False\n",
      " False  True False False  True False False  True  True  True  True  True\n",
      " False False False False  True  True  True False False False False False\n",
      "  True  True False False False  True False False  True False False False\n",
      "  True  True  True  True False False False False False False False False\n",
      " False False  True False False  True False False  True  True  True False\n",
      "  True  True False False False False False False  True False False  True\n",
      " False False False False False  True False False False False  True False\n",
      " False  True  True  True False  True False False False  True False  True\n",
      "  True False False False False  True  True  True  True False False False\n",
      " False False  True False False False False  True False  True False  True\n",
      "  True  True  True False False  True False False False False  True  True\n",
      " False False False False False False  True False False  True  True False\n",
      "  True False False  True  True  True  True False False False False False\n",
      "  True False False False  True  True False False  True False  True  True\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False  True False  True  True False False  True\n",
      "  True False  True False False False False  True  True  True False False\n",
      " False  True  True False  True False False False  True False  True False\n",
      " False False False  True False  True False  True False False False False\n",
      " False  True  True  True  True False  True False False False False  True\n",
      " False False False  True False  True False False False False False False\n",
      " False False  True False  True False False  True False False  True False\n",
      " False  True False False  True  True False False  True False  True  True\n",
      " False  True False False False  True False False False False  True  True\n",
      " False  True False False  True  True False False False  True  True False\n",
      " False False False False False  True  True  True  True  True False  True\n",
      "  True False False False False False  True False  True  True False False\n",
      " False False False False False  True  True False False False False False\n",
      " False  True False False False False False  True  True  True False False\n",
      " False False False  True False False  True False  True False  True False\n",
      "  True False  True False False False False False False False False False\n",
      " False  True  True False  True  True False False  True False  True False\n",
      " False False False  True  True False False False False False  True False\n",
      " False False  True  True False  True False  True False False False False]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing the test set using the preprocessor\n",
    "X_test_encoded = preprocessor.transform(X_test)\n",
    "\n",
    "# Using the best model from the hyperparameter search \n",
    "y_test_pred = dt_model_min_samples.predict(X_test_encoded)\n",
    "\n",
    "# Printing predictions for the test set\n",
    "print(f\"Test Set Predictions:\\n{y_test_pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23 Summarize what you learned along the way and make recommendations to your boss on how this could be used moving forward, being careful not to over promise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is doing great on the training, tuning, and test sets, but I’m concerned it might be overfitting and could have trouble with new data. I think we should test it with real-world data and try techniques like cross-validation to make it more reliable. Moving forward, I can use the model to predict movie success, but I’ll need to keep an eye on its performance to make sure it stays accurate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
